/**
 * LLM ì¶œë ¥ í›„ì²˜ë¦¬ ëª¨ë“ˆ
 * - ê¸ˆì¹™ì–´ ìë™ ì¹˜í™˜
 * - ì˜ë£Œë²• ìœ„ë°˜ í‘œí˜„ ìë™ ì¹˜í™˜
 * - ~ìš” ê¸ˆì§€ ì–´ë¯¸ ì¹˜í™˜ (ì•ˆì „ íŒ¨í„´ë§Œ)
 * - í˜•íƒœì†Œ ê¸°ë°˜ í‚¤ì›Œë“œ ë¹ˆë„ ì¡°ì ˆ
 * - ë™ì˜ì–´ íšŒì „ ê°•ì œ ì ìš©
 */

import { SYNONYM_DICTIONARY } from '@/data/synonyms'

// ============================================================
// ìœ í‹¸ë¦¬í‹°
// ============================================================

/** í•œê¸€ ë¬¸ìì˜ ë°›ì¹¨(ì¢…ì„±) ìœ ë¬´ íŒë³„ */
function hasBatchim(char: string): boolean {
  const code = char.charCodeAt(0)
  if (code < 0xAC00 || code > 0xD7A3) return false
  return (code - 0xAC00) % 28 !== 0
}

/** ë°›ì¹¨ì— ë”°ë¥¸ ì¡°ì‚¬ ë³´ì • */
function adjustParticle(word: string, particle: string): string {
  if (!word || word.length === 0) return particle
  const lastChar = word[word.length - 1]
  const batch = hasBatchim(lastChar)

  // [ë°›ì¹¨ ìˆì„ ë•Œ, ë°›ì¹¨ ì—†ì„ ë•Œ]
  const map: Record<string, [string, string]> = {
    'ì´': ['ì´', 'ê°€'], 'ê°€': ['ì´', 'ê°€'],
    'ì„': ['ì„', 'ë¥¼'], 'ë¥¼': ['ì„', 'ë¥¼'],
    'ì€': ['ì€', 'ëŠ”'], 'ëŠ”': ['ì€', 'ëŠ”'],
    'ê³¼': ['ê³¼', 'ì™€'], 'ì™€': ['ê³¼', 'ì™€'],
    'ìœ¼ë¡œ': ['ìœ¼ë¡œ', 'ë¡œ'], 'ë¡œ': ['ìœ¼ë¡œ', 'ë¡œ'],
  }

  const pair = map[particle]
  if (!pair) return particle
  return batch ? pair[0] : pair[1]
}

function escapeRegex(str: string): string {
  return str.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')
}

// ì¡°ì‚¬ íŒ¨í„´ (ê¸´ ê²ƒ ë¨¼ì € ë§¤ì¹­)
const PARTICLE_PATTERN = /^(ì—ì„œ|ìœ¼ë¡œ|ë¼ê³ |ë¼ëŠ”|ì´ë‚˜|ì—ëŠ”|ì—ë„|ê¹Œì§€|ë¶€í„°|ì—|ì˜|ì´|ê°€|ì„|ë¥¼|ì€|ëŠ”|ë¡œ|ì™€|ê³¼|ë„|ë€|ë¼)/

// ============================================================
// 1. ê¸ˆì¹™ì–´ ìë™ ì¹˜í™˜
// ============================================================

const FORBIDDEN_REPLACEMENTS: Record<string, string> = {
  'ê±±ì •': 'ì—¼ë ¤',
  'ê³ ë¯¼': 'ê³ ë ¤',
  'ê³ í†µ': 'í†µì¦',
  'ê³ ìƒ': 'ìˆ˜ê³ ',
  'ê³µìœ ': 'ì•ˆë‚´',
  'ë„ˆë¬´': 'ë§¤ìš°',
  'ë¬´ì²™': 'ìƒë‹¹íˆ',
  'ë¶ˆì•ˆ': 'ìš°ë ¤',
  // 'ë¶ˆí¸': 'ë¶ˆí¸ê°',  <-- Regexë¡œ ì´ë™
  'í˜ë“¤': 'ì–´ë ¤ìš´',
  'í•´ê²°': 'ê°œì„ ',
  'í•´ì†Œ': 'ì™„í™”',
  'í•´ì£¼': 'ë„ì™€ë“œë¦¬',
  'í•´ë³´': 'ì‚´í´ë³´',
  'í•´ë³¸': 'ê²ªì–´ë³¸',
  // 'ê³¼ë„': 'ì§€ë‚˜ì¹œ', <-- Regexë¡œ ì´ë™
  'ê³¼ë‹¤': 'ê³¼ì‰',
  // 'ê³¼í•¨': 'ì§€ë‚˜ì¹¨',
  // 'í•„ìš”/ë§Œì¡±/ê²½í—˜': ë¬¸ë§¥ íƒ€ëŠ” ë‹¨ì–´ëŠ” ë‹¨ìˆœ ì¹˜í™˜ ì œì™¸
}

/** ê¸ˆì¹™ì–´ë¥¼ ì•ˆì „í•œ ëŒ€ì²´ì–´ë¡œ ì¹˜í™˜ (ë…ë¦½ ë‹¨ì–´ ê¸°ì¤€, í•œê¸€ ì¡°ì‚¬ ë³´ì • í¬í•¨) */
export function sanitizeForbiddenWords(content: string): string {
  let result = content

  // ì•ìª½ ê²½ê³„: ê³µë°±/ë¬¸ì¥ë¶€í˜¸/ì‹œì‘
  const BOUNDARY_BEFORE = `(^|[\\s,.\\'"\u201C\u201D\u00B7(])`

  for (const [word, replacement] of Object.entries(FORBIDDEN_REPLACEMENTS)) {
    // replacementê°€ wordë¥¼ í¬í•¨í•˜ë©´ ë¬´í•œ êµì²´ ë°©ì§€ (ì˜ˆ: ë¶ˆí¸â†’ë¶ˆí¸ê°)
    let negLookahead = ''
    if (replacement.startsWith(word) && replacement.length > word.length) {
      const suffix = replacement.slice(word.length)
      negLookahead = `(?!${escapeRegex(suffix)})`
    }

    // 1ë‹¨ê³„: ë‹¨ì–´ + ì¡°ì‚¬ â†’ ì¡°ì‚¬ ë³´ì • í¬í•¨ ì¹˜í™˜
    const withParticle = new RegExp(
      `${BOUNDARY_BEFORE}${escapeRegex(word)}${negLookahead}(ì—ì„œ|ìœ¼ë¡œ|ë¼ê³ |ë¼ëŠ”|ì´ë‚˜|ì—ëŠ”|ì—ë„|ê¹Œì§€|ë¶€í„°|ì—|ì˜|ì´|ê°€|ì„|ë¥¼|ì€|ëŠ”|ë¡œ|ì™€|ê³¼|ë„|ë€|ë¼)(?=[\\s,.\\'"\u201C\u201D\u00B7)!?\\n\uAC00-\uD7A3]|$)`,
      'gm'
    )
    result = result.replace(withParticle, (_match, prefix, particle) => {
      const adjusted = adjustParticle(replacement, particle)
      return prefix + replacement + adjusted
    })

    // 2ë‹¨ê³„: ë‹¨ì–´ ë‹¨ë… (ë’¤: ê³µë°±/êµ¬ë‘ì /í•œê¸€/ë)
    const alone = new RegExp(
      `${BOUNDARY_BEFORE}${escapeRegex(word)}${negLookahead}(?=[\\s,.\\'"\u201C\u201D\u00B7)!?\\n\uAC00-\uD7A3]|$)`,
      'gm'
    )
    result = result.replace(alone, `$1${replacement}`)
  }

  return result
}

// ============================================================
// 1.5. ì˜ë£Œë²• ìœ„ë°˜ í‘œí˜„ ìë™ ì¹˜í™˜
// ============================================================

const MEDICAL_REPLACEMENTS: [RegExp, string][] = [
  [/ë¬´í†µ(?!ì¦)/g, 'ì €í†µì¦'],
  [/í†µì¦\s*ì—†ëŠ”/g, 'í†µì¦ì„ ì¤„ì´ëŠ”'],
  [/ì•„í”„ì§€\s*ì•Š/g, 'í†µì¦ì´ ì '],
  [/ì™„ë²½í•œ\s*ì¹˜ë£Œ/g, 'ì •ë°€í•œ ì¹˜ë£Œ'],
  [/ì™„ë²½í•œ\s*ì‹œìˆ /g, 'ì •ë°€í•œ ì‹œìˆ '],
  [/ì™„ë²½í•œ\s*ê²°ê³¼/g, 'ì–‘í˜¸í•œ ê²°ê³¼'],
  [/ì´ë¹¨/g, 'ì¹˜ì•„'],
  [/ë•Œìš°ê¸°/g, 'ìˆ˜ë³µ ì¹˜ë£Œ'],
  [/ì”Œìš°ê¸°/g, 'ë³´ì²  ì¹˜ë£Œ'],
  // í™˜ì ì§ì ‘ ì–¸ê¸‰ â†’ ì¼ë°˜í™” í‘œí˜„ìœ¼ë¡œ ì¹˜í™˜
  [/í™˜ìë¶„ì˜\s*êµ¬ê°•/g, 'ê°œì¸ë³„ êµ¬ê°•'],
  [/í™˜ìë¶„ê»˜ì„œ/g, 'ì´ëŸ° ê²½ìš°'],
  [/í™˜ì\s*ì…ì¥ì—ì„œ/g, 'ì‹œìˆ ì„ ë°›ìœ¼ì‹œëŠ” ë¶„ ì…ì¥ì—ì„œ'],
  [/í™˜ìë¶„ì´/g, 'í•´ë‹¹ë˜ì‹œëŠ” ë¶„ì´'],
  // íš¨ê³¼ ë³´ì¥/ì¶”ì²œ í‘œí˜„
  [/í˜„ëª…í•œ\s*ì„ íƒ/g, 'ì í•©í•œ ë°©ë²•'],
  // ë¹„í‘œì¤€ ìš©ì–´ ì¹˜í™˜
  [/í¬ë¼ìš´/g, 'ë³´ì² '],
  [/ë„ê¸ˆì†/g, 'ë„ì¬-ê¸ˆì†'],
  [/ì‹¬ëŠ”ë‹¤/g, 'ì‹ë¦½í•œë‹¤'],
  [/ì‹¬ì„\s*ìˆ˜/g, 'ì‹ë¦½í•  ìˆ˜'],
  [/ì‹¬ì–´/g, 'ì‹ë¦½í•˜ì—¬'],
  // ì „ë¬¸ ìš©ì–´ ì •ê·œí™” (ì‹¤ë¬´ì í”¼ë“œë°±)
  [/í”½ìŠ¤ì³/g, 'í”½ìŠ¤ì²˜'],
  [/ì„í”Œë€íŠ¸\s*ì‹ë¦½/g, 'í”½ìŠ¤ì²˜ ì‹ë¦½'],
  [/ì£¼ë³€\s*ì¹˜ì•„/g, 'ì¸ì ‘ì¹˜'],
  [/ì˜†\s*ì¹˜ì•„/g, 'ì¸ì ‘ì¹˜'],
  [/ë°˜ëŒ€í¸\s*ì¹˜ì•„/g, 'ëŒ€í•©ì¹˜'],
  [/ì¹˜ì•„\s*ì‚¬ì´ê°€/g, 'ì¹˜ê°„ì´'],
  [/ì¹˜ì•„\s*ì‚¬ì´ëŠ”/g, 'ì¹˜ê°„ì€'],
  [/ì¹˜ì•„\s*ì‚¬ì´ë¥¼/g, 'ì¹˜ê°„ì„'],
  [/ì¹˜ì•„\s*ì‚¬ì´/g, 'ì¹˜ê°„'], // ê¸°ë³¸í˜•
  // ë¬¸ë§¥ ê³ ë ¤ ì¹˜í™˜ (ë¶ˆí¸í•œ -> ë¶ˆí¸ê°í•œ ë°©ì§€)
  [/ë¶ˆí¸(?![í•˜í•œí•´])/g, 'ë¶ˆí¸ê°'],
  [/ê³¼ë„í•œ/g, 'ì§€ë‚˜ì¹œ'],
  [/ê³¼ë„í•˜ê²Œ/g, 'ì§€ë‚˜ì¹˜ê²Œ'],
  [/ê³¼í•¨/g, 'ì§€ë‚˜ì¹¨'],
  // ë¬¸ë²• ë§ì¶¤ ì¹˜í™˜ (í•„ìš” -> ê¶Œì¥ë˜ëŠ”í•œ/ìš”êµ¬ë˜ëŠ”í•©ë‹ˆë‹¤ ë°©ì§€)
  [/í•„ìš”í•©ë‹ˆë‹¤/g, 'ê¶Œì¥ë©ë‹ˆë‹¤'],
  [/í•„ìš”í•œ/g, 'ê¶Œì¥ë˜ëŠ”'],
  [/í•„ìš”í• \s*ìˆ˜/g, 'ê¶Œì¥ë  ìˆ˜'],
  [/í•„ìš”ì‹œ/g, 'í•„ìš” ì‹œ'],
]

/** ì˜ë£Œë²• ìœ„ë°˜ ê°€ëŠ¥ í‘œí˜„ì„ ì•ˆì „í•œ í‘œí˜„ìœ¼ë¡œ ìë™ ì¹˜í™˜ */
export function sanitizeMedicalExpressions(content: string): string {
  let result = content
  for (const [pattern, replacement] of MEDICAL_REPLACEMENTS) {
    result = result.replace(pattern, replacement)
  }
  return result
}

// ============================================================
// 2. ~ìš” ê¸ˆì§€ ì–´ë¯¸ ì¹˜í™˜ (ì•ˆì „ íŒ¨í„´ë§Œ, ë¬¸ì¥ ëì—ì„œë§Œ)
// ============================================================

/**
 * ì•ˆì „í•˜ê²Œ ì¹˜í™˜ ê°€ëŠ¥í•œ ì–´ë¯¸ë§Œ ì²˜ë¦¬
 * - ë¬¸ì¥ ë(. ! ? ì¤„ë°”ê¿ˆ ì•)ì—ì„œë§Œ ë§¤ì¹­
 * - "ì„¸ìš”"ëŠ” í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ â†’ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
 * - "ë„¤ìš”", "ê±°ë“ ìš”"ëŠ” í˜•íƒœì†Œ ì˜ì¡´ì  â†’ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
 * - writingModeì— ë”°ë¼ "ì¸ë°ìš”" ì²˜ë¦¬ ë¶„ê¸°
 */
export function sanitizeForbiddenEndings(content: string, writingMode?: string): string {
  let result = content

  // ì•ˆì „í•œ ì¹˜í™˜ ëª©ë¡ (ë¬¸ë²•ì ìœ¼ë¡œ 1:1 ëŒ€ì‘ ê°€ëŠ¥í•œ ê²ƒë§Œ)
  const safePatterns: [RegExp, string][] = [
    [/í•´ìš”(?=[.!?\s\n]|$)/g, 'í•©ë‹ˆë‹¤'],
    [/ìˆì–´ìš”(?=[.!?\s\n]|$)/g, 'ìˆìŠµë‹ˆë‹¤'],
    [/ë“œë ¤ìš”(?=[.!?\s\n]|$)/g, 'ë“œë¦½ë‹ˆë‹¤'],
    [/í• ê²Œìš”(?=[.!?\s\n]|$)/g, 'í•˜ê² ìŠµë‹ˆë‹¤'],
    [/ë³¼ê²Œìš”(?=[.!?\s\n]|$)/g, 'ë³´ê² ìŠµë‹ˆë‹¤'],
    [/ì¤„ê²Œìš”(?=[.!?\s\n]|$)/g, 'ë“œë¦¬ê² ìŠµë‹ˆë‹¤'],
  ]

  // ì„ìƒ ëª¨ë“œì—ì„œë§Œ "ì¸ë°ìš”" ì œê±° (ì •ë³´ì„± ëª¨ë“œì—ì„œëŠ” 10% í—ˆìš©)
  if (writingMode === 'expert') {
    safePatterns.push([/ì¸ë°ìš”(?=[.!?\s\n]|$)/g, 'ì¸ë°'])
  }

  for (const [pattern, replacement] of safePatterns) {
    result = result.replace(pattern, replacement)
  }

  return result
}

// ============================================================
// 3. í˜•íƒœì†Œ ê¸°ë°˜ í‚¤ì›Œë“œ ë¹ˆë„ êµì •
// ============================================================

// ì¹˜ë£Œ ê´€ë ¨ ë³µí•©ì–´ â€” ë‚´ë¶€ì˜ ë¶€ë¶„ ë‹¨ì–´ë¥¼ êµì²´í•˜ë©´ ì•ˆ ë¨
const PROTECTED_COMPOUNDS = [
  'ê·¼ê´€ì¹˜ë£Œ', 'ì‹ ê²½ì¹˜ë£Œ', 'êµì •ì¹˜ë£Œ', 'ì¹˜ì£¼ì¹˜ë£Œ', 'ë³´ì¡´ì¹˜ë£Œ',
  'ë³´ì² ì¹˜ë£Œ', 'ë ˆì´ì €ì¹˜ë£Œ', 'ë¶ˆì†Œì¹˜ë£Œ', 'ì‡ëª¸ì¹˜ë£Œ', 'ì˜ˆë°©ì¹˜ë£Œ',
  'ì‘ê¸‰ì¹˜ë£Œ', 'ë³´ì¡´ì ì¹˜ë£Œ', 'ì¬ì‹ ê²½ì¹˜ë£Œ',
  'ì¸ê³µì¹˜ì•„', 'ìì—°ì¹˜ì•„', 'ì„ì‹œì¹˜ì•„', 'ì˜êµ¬ì¹˜ì•„',
]

/** íŠ¹ì • ë‹¨ì–´ì˜ ì¶œí˜„ ìœ„ì¹˜ ì¤‘ ë³µí•©ì–´ì— ì†í•˜ì§€ ì•ŠëŠ” ì•ˆì „í•œ ìœ„ì¹˜ë§Œ ë°˜í™˜ */
function findSafeOccurrences(content: string, word: string): number[] {
  const regex = new RegExp(escapeRegex(word), 'g')
  const safeIndices: number[] = []
  let match: RegExpExecArray | null

  while ((match = regex.exec(content)) !== null) {
    const idx = match.index
    const isProtected = PROTECTED_COMPOUNDS.some(compound => {
      if (!compound.includes(word) || compound === word) return false
      const wordPosInCompound = compound.indexOf(word)
      const compoundStart = idx - wordPosInCompound
      if (compoundStart < 0 || compoundStart + compound.length > content.length) return false
      return content.substring(compoundStart, compoundStart + compound.length) === compound
    })
    if (!isProtected) {
      safeIndices.push(idx)
    }
  }

  return safeIndices
}

/** ë‹¨ì¼ ë‹¨ì–´ êµì²´ (ì¡°ì‚¬ ë³´ì • í¬í•¨), ì¸ë±ìŠ¤ ê¸°ì¤€ */
function replaceAtIndex(
  content: string,
  index: number,
  oldWord: string,
  newWord: string
): string {
  const before = content.substring(0, index)
  const after = content.substring(index + oldWord.length)

  // ë’¤ì— ì¡°ì‚¬ê°€ ë¶™ì–´ìˆìœ¼ë©´ ë³´ì •
  const particleMatch = after.match(PARTICLE_PATTERN)
  if (particleMatch) {
    const oldParticle = particleMatch[1]
    const newParticle = adjustParticle(newWord, oldParticle)
    return before + newWord + newParticle + after.substring(oldParticle.length)
  }

  return before + newWord + after
}

/** ë‹¨ì–´ê°€ maxCountë¥¼ ì´ˆê³¼í•˜ë©´ ë’¤ìª½ë¶€í„° ë™ì˜ì–´ë¡œ êµì²´ */
function reduceWordCount(
  content: string,
  word: string,
  maxCount: number,
  synonyms: string[]
): string {
  if (synonyms.length === 0) return content

  // ë‹¨ì¼ ë‹¨ì–´ ë™ì˜ì–´ë§Œ ì‚¬ìš© (ì—¬ëŸ¬ ë‹¨ì–´ ë™ì˜ì–´ëŠ” ì¡°ì‚¬ ë³´ì •ì´ ì–´ë ¤ì›€)
  const safeSynonyms = synonyms.filter(s => !s.includes(' '))
  if (safeSynonyms.length === 0) return content

  const safeOccurrences = findSafeOccurrences(content, word)
  if (safeOccurrences.length <= maxCount) return content

  // ì•ìª½ maxCountê°œëŠ” ë³´ì¡´, ë‚˜ë¨¸ì§€ë¥¼ ë’¤ì—ì„œë¶€í„° êµì²´
  const toReplace = safeOccurrences.slice(maxCount)
  let result = content

  // ë’¤ì—ì„œë¶€í„° êµì²´í•´ì•¼ ì¸ë±ìŠ¤ê°€ ë°€ë¦¬ì§€ ì•ŠìŒ
  for (let i = toReplace.length - 1; i >= 0; i--) {
    const synonym = safeSynonyms[i % safeSynonyms.length]
    result = replaceAtIndex(result, toReplace[i], word, synonym)
  }

  return result
}

/**
 * í˜•íƒœì†Œ ê¸°ë°˜ í‚¤ì›Œë“œ ë¹ˆë„ ì œí•œ
 *
 * ë©”ì¸í‚¤ì›Œë“œ = í˜•íƒœì†ŒA(region) + í˜•íƒœì†ŒB(ì¹˜ê³¼ or topic)
 * ê° í˜•íƒœì†Œ ëª©í‘œ 7íšŒ â†’ 8íšŒ ì´ˆê³¼ ì‹œ ì¶•ì†Œ
 *
 * - "ì§€ì—­+ì¹˜ê³¼" íƒ€ì…: morphemeB = "ì¹˜ê³¼", topicì€ ì„œë¸Œí‚¤ì›Œë“œ(ë³„ë„ max 5)
 * - "ì§€ì—­+ì§„ë£Œ" íƒ€ì…: morphemeB = topic, topicì€ ì´ë¯¸ 7íšŒì— í¬í•¨
 */
export function enforceMorphemeLimit(
  content: string,
  options: PostProcessOptions
): string {
  let result = content
  const { region, mainKeyword, topic } = options

  // morphemeB ì¶”ì¶œ: mainKeywordì—ì„œ region ì œê±°
  const morphemeB = mainKeyword.replace(region, '').trim() || 'ì¹˜ê³¼'

  // í˜•íƒœì†ŒB ë¹ˆë„ ì œí•œ (7íšŒ ì´ˆê³¼ ì‹œ ë™ì˜ì–´ êµì²´)
  if (morphemeB) {
    const synonymsB = SYNONYM_DICTIONARY[morphemeB]
    if (synonymsB && synonymsB.length > 0) {
      result = reduceWordCount(result, morphemeB, 7, synonymsB)
    }
  }

  // topicì´ morphemeBì™€ ë‹¤ë¥¸ ê²½ìš° = ì„œë¸Œí‚¤ì›Œë“œ â†’ max 5
  if (topic && topic !== morphemeB) {
    const topicSynonyms = SYNONYM_DICTIONARY[topic]
    if (topicSynonyms && topicSynonyms.length > 0) {
      result = reduceWordCount(result, topic, 5, topicSynonyms)
    }
  }

  return result
}

// ============================================================
// 4. ë™ì˜ì–´ íšŒì „ (ê³ ë¹ˆë„ ì¼ë°˜ ë‹¨ì–´)
// ============================================================

const WATCH_WORDS = ['ì¹˜ë£Œ', 'ì‹œìˆ ', 'ìˆ˜ìˆ ', 'ì§„í–‰', 'í™•ì¸', 'ìƒíƒœ', 'ê²½ìš°', 'í•„ìš”']

/**
 * ë™ì˜ì–´ íšŒì „ ê°•ì œ ì ìš©
 * - ì „ì²´ 6íšŒ ì´í•˜ë¡œ ìœ ì§€
 * - ì„¹ì…˜(##)ë‹¹ 3íšŒ ì´í•˜ë¡œ ìœ ì§€
 * - ì´ë¯¸ ì²˜ë¦¬ëœ ë‹¨ì–´ì˜ ë™ì˜ì–´ëŠ” ê±´ë„ˆëœ€ (ì—°ì‡„ êµì²´ ë°©ì§€)
 * - morphemeBê°€ ë³µí•©ì–´(ê·¼ê´€ì¹˜ë£Œ ë“±)ì´ë©´ í•´ë‹¹ ë‹¨ì–´ëŠ” ë™ì˜ì–´ íšŒì „ì—ì„œ ë³´í˜¸
 */
/**
 * ë™ì˜ì–´ íšŒì „ ê°•ì œ ì ìš© (ì „ì²´ ë‹¨ì–´ ëŒ€ìƒ)
 * - Region, Clinic, MainKeywordë¥¼ ì œì™¸í•œ ëª¨ë“  ë‹¨ì–´ëŠ” ì „ì²´ 6íšŒ ì´ˆê³¼ ì‹œ êµì²´
 * - MainKeywordì™€ ê²¹ì¹˜ëŠ” êµ¬ê°„ì€ ë³´í˜¸
 */
export function rotateSynonyms(content: string, options: PostProcessOptions): string {
  let result = content
  const { region, mainKeyword, clinicName } = options

  // 1. ë³´í˜¸ êµ¬ê°„ ì‹ë³„ (Main Keyword, Clinic Name)
  const protectedRanges: [number, number][] = []
  const inputKeywords = [mainKeyword, clinicName].filter(Boolean) as string[]

  for (const kw of inputKeywords) {
    const kwRegex = new RegExp(escapeRegex(kw), 'g')
    for (const match of result.matchAll(kwRegex)) {
      if (match.index !== undefined) {
        protectedRanges.push([match.index, match.index + kw.length])
      }
    }
  }

  // ê²¹ì¹¨ í™•ì¸ í—¬í¼
  const isProtected = (start: number, end: number) => {
    return protectedRanges.some(([pStart, pEnd]) =>
      (start < pEnd && end > pStart)
    )
  }

  // 2. ì˜ˆì™¸ ë‹¨ì–´ ì„¤ì •
  const exceptions = new Set([
    region,
    clinicName,
    'ì¹˜ê³¼', // ëª…ì‹œì  ì œì™¸
    'ì›ì¥', // í•„ìš” ì‹œ ì¶”ê°€
    ...inputKeywords
  ].filter(Boolean))

  // 3. ì‚¬ì „ ìˆœíšŒ ë° êµì²´
  for (const [word, synonyms] of Object.entries(SYNONYM_DICTIONARY)) {
    if (exceptions.has(word)) continue
    if (!synonyms || synonyms.length === 0) continue

    const regex = new RegExp(escapeRegex(word), 'g')
    // í˜„ì¬ ê²°ê³¼ì—ì„œ ë§¤ì¹˜ ì°¾ê¸°
    const allMatches = [...result.matchAll(regex)]

    // ë³´í˜¸ êµ¬ê°„ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ìœ íš¨ ë§¤ì¹˜ í•„í„°ë§
    const validMatches = allMatches.filter(m =>
      m.index !== undefined && !isProtected(m.index, m.index + word.length)
    )

    // 6íšŒ ì´ˆê³¼ ì‹œ êµì²´
    if (validMatches.length > 6) {
      // 7ë²ˆì§¸(ì¸ë±ìŠ¤ 6)ë¶€í„° êµì²´ ëŒ€ìƒ
      const matchesToReplace = validMatches.slice(6)
      const safeSynonyms = synonyms.filter(s => !s.includes(' ')) // ê³µë°± ì—†ëŠ” ë‹¨ì–´ ìš°ì„ 

      if (safeSynonyms.length === 0) continue

      // ë’¤ì—ì„œë¶€í„° êµì²´ (ì¸ë±ìŠ¤ ë°€ë¦¼ ë°©ì§€)
      // ì£¼ì˜: matchesToReplaceëŠ” ì•ì—ì„œë¶€í„° ì •ë ¬ë˜ì–´ ìˆìŒ. ì—­ìˆœ ìˆœíšŒ í•„ìš”.
      for (let i = matchesToReplace.length - 1; i >= 0; i--) {
        const match = matchesToReplace[i]
        if (match.index === undefined) continue

        const synonym = safeSynonyms[i % safeSynonyms.length] // ìˆœí™˜ ì„ íƒ

        const before = result.slice(0, match.index)
        const after = result.slice(match.index + word.length)
        result = before + synonym + after
      }

      // ì£¼ì˜: resultê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ìŒ ë£¨í”„ì˜ protectedRangesëŠ” ì˜¤ì°¨ ë°œìƒ ê°€ëŠ¥?
      // ì•„ë‹ˆì˜¤, protectedRangesëŠ” Main Keyword ìœ„ì¹˜ì„.
      // ìš°ë¦¬ê°€ êµì²´í•œ ê²ƒì€ Main Keywordê°€ "ì•„ë‹Œ" ë‹¨ì–´ë“¤ì„.
      // ë‹¨, êµì²´ë¡œ ì¸í•´ ì „ì²´ ê¸¸ì´ ë°”ë€Œë©´ Main Keyword ìœ„ì¹˜ë„ ë°”ë€œ.
      // ë”°ë¼ì„œ, ì •í™•ì„±ì„ ìœ„í•´ protectedRangesë¥¼ ë§¤ë²ˆ ê°±ì‹ í•˜ê±°ë‚˜,
      // **ê°€ì¥ ì•ˆì „í•œ ë°©ë²•**: ë³€ê²½ëœ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ì‹œ ê²€ìƒ‰? ì„±ëŠ¥ ì €í•˜.
      // **ì ˆì¶©**: ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ, ì´ ë‹¨ì–´(word)ì— ëŒ€í•œ ì²˜ë¦¬ëŠ” ì•ˆì „í•¨.
      // ë‹¤ë¥¸ ë‹¨ì–´(next word) ì²˜ë¦¬ ì‹œ protectedRangesê°€ ì•ˆ ë§ì„ ìˆ˜ ìˆìŒ.
      // í•´ê²°ì±…: í…ìŠ¤íŠ¸ ë³€ê²½ ì‹œ protectedRangesë„ ì‹œí”„íŠ¸? ë³µì¡í•¨.
      // **ì‹¤ìš©ì  í•´ê²°ì±…**: ë£¨í”„ë§ˆë‹¤ protectedRanges ì¬ê³„ì‚°? (ë‹¨ì–´ 50ê°œ * ë§¤ì¹˜. ì¢€ ë¬´ê±°ì›€)
      // í•˜ì§€ë§Œ ë¸”ë¡œê·¸ ê¸€ì€ 3000ì. ë¹ ë¦„. ì¬ê³„ì‚°í•˜ì.

      // ì¬ê³„ì‚° ë¡œì§ ì‚½ì… (ì„±ëŠ¥ë³´ë‹¤ ì •í™•ì„±)
      protectedRanges.length = 0
      for (const kw of inputKeywords) {
        const kwRegex = new RegExp(escapeRegex(kw), 'g')
        for (const match of result.matchAll(kwRegex)) {
          if (match.index !== undefined) {
            protectedRanges.push([match.index, match.index + kw.length])
          }
        }
      }
    }
  }

  return result
}

// ============================================================
// 5. í˜•íƒœì†Œ(ì§€ì—­ëª…) ë¹ˆë„ ë° ë¶„í¬ ë³´ì¥ (7íšŒ ê³ ì •: ì œëª©1+ì„œë¡ 1+ë³¸ë¡ 4+ê²°ë¡ 1)
// ============================================================

/** ë³¸ë¡ ìš© ë¸Œë¦¿ì§€ ë¬¸ì¥ (ë‹¤ì–‘ì„± í™•ë³´) */
function getBridgeSentences(region: string): string[] {
  return [
    `${region} ë°©ë¬¸ ì‹œ ì´ ì ì„ ì²´í¬í•´ë³´ì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.`,
    `${region}ì—ì„œ ê¾¸ì¤€í•œ ê²€ì§„ì„ ë°›ìœ¼ì‹œê¸¸ ê¶Œì¥í•©ë‹ˆë‹¤.`,
    `ê°€ê¹Œìš´ ${region} ì¹˜ê³¼ì—ì„œ í˜„ì¬ ìƒíƒœë¥¼ í™•ì¸í•´ë³´ëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤.`,
    `${region}ì—ì„œ ì •ë°€ ê²€ì‚¬ë¥¼ í†µí•´ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`,
    `${region} ë°©ë¬¸ì„ í†µí•´ ì •í™•í•œ ì§„ë‹¨ì„ ë°›ì•„ë³´ì„¸ìš”.`,
    `${region}ì—ì„œ ì²´ê³„ì ì¸ ê´€ë¦¬ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”.`,
    `${region} ì „ë¬¸ì˜ì™€ ìƒë‹´í•˜ì—¬ ê³„íšì„ ì„¸ì›Œë³´ì„¸ìš”.`,
    `${region}ì—ì„œë„ ì´ì™€ ìœ ì‚¬í•œ ì‚¬ë¡€ê°€ ì ì§€ ì•ŠìŠµë‹ˆë‹¤.`,
    `${region} ì§€ì—­ì—ì„œë„ ì´ì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.`,
    `${region}ì—ì„œë„ ì´ëŸ¬í•œ ì¦ìƒìœ¼ë¡œ ë‚´ì›í•˜ì‹œëŠ” ë¶„ë“¤ì´ ë§ìŠµë‹ˆë‹¤.`,
    `${region} ì§€ì—­ì—ì„œ ì •ê¸°ì ì¸ ê´€ë¦¬ê°€ ê¶Œì¥ë©ë‹ˆë‹¤.`,
    `${region}ì—ì„œë„ ìœ ì‚¬í•œ ì¦ë¡€ê°€ ë³´ê³ ë˜ê³  ìˆìŠµë‹ˆë‹¤.`,
  ]
}

/**
 * ì§€ì—­ëª… ë¹ˆë„ ë° ë¶„í¬ ê°•ì œ (ì´ 7íšŒ)
 * - ì œëª©(1), ì„œë¡ (1), ë³¸ë¡ (4), ê²°ë¡ (1)
 * - ë¶€ì¡± ì‹œ ë¸Œë¦¿ì§€ ë¬¸ì¥ ì‚½ì…
 */
export function enforceRegionFrequency(content: string, region: string): string {
  if (!region) return content

  // 1. ì„¹ì…˜ ë¶„ë¦¬
  // Intro(ì œëª©í¬í•¨) | Body(## ...) | Conclusion(ë§ˆì§€ë§‰ ## ...)
  const sections = content.split(/^(##\s.*$)/m)

  // í—¤ë” ê°œìˆ˜ íŒŒì•…
  let headerCount = 0
  for (const s of sections) {
    if (/^##\s/.test(s)) headerCount++
  }

  // êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥´ë©´(í—¤ë”ê°€ ë„ˆë¬´ ì ìœ¼ë©´) ë‹¨ìˆœ ì „ì²´ ì‚½ì…ìœ¼ë¡œ fallback
  if (headerCount < 2) return content

  // Conclusionì€ ë§ˆì§€ë§‰ í—¤ë” + ë‚´ìš©
  const conclusionHeaderIdx = sections.length - 2
  const conclusionContentIdx = sections.length - 1

  // IntroëŠ” ì²« ë²ˆì§¸ ì„¹ì…˜ (ì œëª© í¬í•¨)
  let introPart = sections[0]

  // BodyëŠ” ê·¸ ì‚¬ì´
  const bodyIndices: number[] = []
  for (let i = 1; i < conclusionHeaderIdx; i += 2) {
    // i: header, i+1: content
    bodyIndices.push(i + 1)
  }

  // 2. ê²€ì‚¬ ë° ë³´ì •

  // [ì„œë¡ ] (ì œëª© ì œì™¸ ì„œë¡  ë³¸ë¬¸ì— 1íšŒ ìˆëŠ”ì§€ í™•ì¸)
  // ì œëª©ì€ ì²« ì¤„ì´ë¼ê³  ê°€ì •. ì„œë¡  ë³¸ë¬¸ì—ì„œ ì²´í¬.
  const introLines = introPart.split('\n')
  const titleLine = introLines[0]
  const introBody = introLines.slice(1).join('\n')

  if (!introBody.includes(region)) {
    // ì„œë¡  ë§ˆì§€ë§‰ì— ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€ (ì´ë¯¸ ìˆìœ¼ë©´ íŒ¨ìŠ¤)
    // ì¸ì‚¬ê°€ ë³´í†µ ë§¨ ì•ì´ë¯€ë¡œ, ë§¨ ë’¤ì— ë¶™ì´ëŠ”ê²Œ ì•ˆì „
    introPart = introPart.trim() + `\n\n${region}ì—ì„œ ì•Œë ¤ë“œë ¸ìŠµë‹ˆë‹¤.`
  }

  // [ë³¸ë¡ ] (ì´ 4íšŒ ë§ì¶”ê¸°)
  let currentBodyCount = 0
  for (const idx of bodyIndices) {
    currentBodyCount += (sections[idx].match(new RegExp(escapeRegex(region), 'g')) || []).length
  }

  if (currentBodyCount < 4) {
    let deficiency = 4 - currentBodyCount
    const bridges = getBridgeSentences(region)
    let bridgeIdx = 0

    // ë³¸ë¡  ì„¹ì…˜ ìˆœíšŒí•˜ë©° ì‚½ì…
    for (const idx of bodyIndices) {
      if (deficiency <= 0) break
      if (sections[idx].includes(region)) continue // ì´ë¯¸ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸° (ë¶„ì‚° ìœ ë„)

      // ì ì ˆí•œ ìœ„ì¹˜(ë¬¸ì¥ ë)ì— ì‚½ì…
      const bridge = bridges[bridgeIdx % bridges.length]
      bridgeIdx++

      // ì²« ë²ˆì§¸ ë§ˆì¹¨í‘œ ë’¤ì— ì‚½ì… ì‹œë„
      const dotMatch = sections[idx].match(/\.\s/)
      if (dotMatch && dotMatch.index !== undefined) {
        const insertPos = dotMatch.index + 2
        sections[idx] = sections[idx].slice(0, insertPos) + bridge + ' ' + sections[idx].slice(insertPos)
        deficiency--
      } else {
        // ë§ˆì¹¨í‘œ ì—†ìœ¼ë©´ ë¬¸ë‹¨ ëì— ì¶”ê°€
        sections[idx] = sections[idx].trim() + `\n\n${bridge}`
        deficiency--
      }
    }

    // í•œ ë°”í€´ ëŒì•˜ëŠ”ë°ë„ ë¶€ì¡±í•˜ë©´(ì„¹ì…˜ ìˆ˜ < ë¶€ì¡±ë¶„), ìˆëŠ” ì„¹ì…˜ì—ë„ ì¶”ê°€
    if (deficiency > 0) {
      for (const idx of bodyIndices) {
        if (deficiency <= 0) break
        const bridge = bridges[bridgeIdx % bridges.length]
        bridgeIdx++
        sections[idx] = sections[idx].trim() + `\n\n${bridge}`
        deficiency--
      }
    }
  }

  // [ê²°ë¡ ] (1íšŒ í™•ì¸)
  const conclusionText = sections[conclusionHeaderIdx] + sections[conclusionContentIdx]
  if (!conclusionText.includes(region)) {
    // ê²°ë¡  ë§ˆì§€ë§‰ ì¸ì‚¬ì— ì¶”ê°€ë˜ì–´ ìˆì„ í™•ë¥  ë†’ì§€ë§Œ, ì—†ìœ¼ë©´ ì¶”ê°€
    sections[conclusionContentIdx] = sections[conclusionContentIdx].trim() + `\n\n${region}ì—ì„œ ì „í•´ë“œë ¸ìŠµë‹ˆë‹¤.`
  }

  // ì¬ì¡°ë¦½ì‹œ introPart ì—…ë°ì´íŠ¸
  sections[0] = introPart

  return sections.join('')
}

// ============================================================
// ë©”ì¸ í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
// ============================================================

export interface PostProcessOptions {
  topic: string
  mainKeyword: string
  clinicName: string
  region: string
  writingMode?: string // 'expert' | 'information'
}

export function postProcess(content: string, options: PostProcessOptions): string {
  let result = content

  // Step 1: ê¸ˆì¹™ì–´ ì¹˜í™˜
  result = sanitizeForbiddenWords(result)

  // Step 1.5: ì˜ë£Œë²• ìœ„ë°˜ í‘œí˜„ ìë™ ì¹˜í™˜
  result = sanitizeMedicalExpressions(result)

  // Step 2: ~ìš” ê¸ˆì§€ ì–´ë¯¸ ì¹˜í™˜ (ì•ˆì „ íŒ¨í„´ë§Œ)
  result = sanitizeForbiddenEndings(result, options.writingMode)

  // Step 3: í˜•íƒœì†Œ ê¸°ë°˜ í‚¤ì›Œë“œ ë¹ˆë„ ì œí•œ
  if (options.region && options.mainKeyword) {
    result = enforceMorphemeLimit(result, options)
  }

  // Step 4: ë™ì˜ì–´ íšŒì „ (ê³ ë¹ˆë„ ì¼ë°˜ ë‹¨ì–´)
  // Step 4: ë™ì˜ì–´ íšŒì „ (ê³ ë¹ˆë„ ì¼ë°˜ ë‹¨ì–´ - ì „ì²´ 6íšŒ ì œí•œ)
  result = rotateSynonyms(result, options)

  // Step 5: í˜•íƒœì†Œ(ì§€ì—­ëª…) ë¹ˆë„ ë° ë¶„í¬ ë³´ì¥ (7íšŒ ê³ ì •)
  if (options.region) {
    result = enforceRegionFrequency(result, options.region)
  }

  // Step 6: ë¬¸ì¥ ì¢…ê²° í›„ ì¤„ë°”ê¿ˆ ë³´ì¥ ('~ë‹¤.' ë’¤ ë‹¤ìŒ ë¬¸ì¥ì€ ìƒˆ ì¤„)
  result = ensureSentenceLineBreaks(result)

  return result
}

/**
 * ë¬¸ì¥ ì¢…ê²°('~ë‹¤.', '~ìš”.', '~ì£ .' ë“±) ë’¤ì— ê°™ì€ ì¤„ì— í…ìŠ¤íŠ¸ê°€ ì´ì–´ì§€ë©´ ì¤„ë°”ê¿ˆ ì‚½ì….
 * ë§ˆí¬ë‹¤ìš´ í—¤ë”, ë¦¬ìŠ¤íŠ¸, í•´ì‹œíƒœê·¸, ì´ë¯¸ì§€, ì¶œì²˜ ë“±ì€ ê±´ë„ˆëœ€.
 */
function ensureSentenceLineBreaks(content: string): string {
  const lines = content.split('\n')
  const result: string[] = []

  for (const line of lines) {
    const trimmed = line.trim()

    // ì¤„ë°”ê¿ˆ ëŒ€ìƒì—ì„œ ì œì™¸
    if (
      trimmed === '' ||
      trimmed.startsWith('#') ||
      trimmed.startsWith('---') ||
      trimmed.startsWith('â€»') ||
      trimmed.startsWith('ğŸ“·') ||
      trimmed.startsWith('Q.') ||
      trimmed.startsWith('A.') ||
      trimmed.startsWith('(ì¶œì²˜:') ||
      trimmed.startsWith('ğŸ’¡') ||
      trimmed.startsWith('- ') ||
      trimmed.startsWith('* ') ||
      /^#[^\s#]/.test(trimmed) ||
      /^\d+\.\s/.test(trimmed)
    ) {
      result.push(line)
      continue
    }

    // ë¬¸ì¥ ì¢…ê²° íŒ¨í„´ ë’¤ì— ê°™ì€ ì¤„ì—ì„œ ìƒˆ ë¬¸ì¥ì´ ì‹œì‘ë˜ë©´ ì¤„ë°”ê¿ˆ ì‚½ì…
    // íŒ¨í„´: í•œê¸€+ì¢…ê²°ì–´ë¯¸+ë§ˆì¹¨í‘œ + ê³µë°± + í•œê¸€/ì´ëª¨ì§€ ì‹œì‘
    const split = line.replace(
      /([ë‹¤ìš”ì£ ê¹Œë‹ˆ][\.!\?])\s+(?=[ê°€-í£A-Zâœ…ğŸ”¹ğŸ”µğŸ’šâš ï¸ğŸ“·"\(])/g,
      '$1\n'
    )
    result.push(split)
  }

  return result.join('\n')
}


